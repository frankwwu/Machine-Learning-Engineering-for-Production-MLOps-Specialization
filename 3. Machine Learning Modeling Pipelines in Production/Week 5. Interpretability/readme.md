## Learning Objectives

* Deconstruct a model to understand and explain how it is making predictions
* Determine tools to make your models explainable to yourself and others in easy to understand terms
* Provide mechanisms to address model fairness and compliance with regulatory requirements
* Differentiate and compare different methods to extract interpretation of models by introspection or explanation
* Distinguish between multiple available techniques such as: Partial Dependance Plots, SHAP and LIME; to provide insight into how model predictions are actually made
* Use cloud managed service for AI explanations

## Explainable AI

Video: LectureExplainable AI . Duration: 6  min

Reading: Explainable AI . Duration: 3 min

Practice Quiz: Explainable AI

## Interpretability

Video: LectureModel Interpretation Methods . Duration: 9 min

Video: LectureIntrinsically Interpretable Models . Duration: 10 min

Reading: Interpretability . Duration: 5 min

Practice Quiz: Interpretability

## Understanding Model Predictions

Video: LectureModel Agnostic Methods . Duration: 1 min

Video: LecturePartial Dependence Plots . Duration: 5 min

Video: LecturePermutation Feature Importance . Duration: 3 min

Reading: Permutation Feature Importance . Duration: 2 min

Lab: Permutation Feature Importance . Duration: 30 min

Video: LectureShapley Values . Duration: 7 min

Video: LectureSHapley Additive exPlanations (SHAP) . Duration: 3 min

Lab: Shapley Values . Duration: 30 min

Reading: Understanding Model Predictions . Duration: 2 min

Video: LectureTesting Concept Activation Vectors . Duration: 3 min

Video: LectureLIME . Duration: 1 min

Reading: TCAV and LIME . Duration: 2 min

Video: LectureAI Explanations . Duration: 5 min

Reading: AI Explanations . Duration: 2 min

Practice Quiz: Understanding Model Predictions

## Course Resources

Reading: Course 3 Optional References . Duration: 10 min

## Acknowledgments

Reading: Acknowledgements . Duration: 3 min
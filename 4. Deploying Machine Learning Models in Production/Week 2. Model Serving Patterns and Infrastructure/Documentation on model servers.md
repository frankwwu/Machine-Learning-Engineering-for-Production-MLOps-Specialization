# Documentation on model servers

The video lecture covered some of the most popular model servers: TensorFlow Serving, TorchServer, KubeFlow Serving and the NVidia Triton inference server.  Here are the links to relevant documentation for each of these options:

* [TensorFlow Serving](https://www.tensorflow.org/tfx/serving/architecture)

* [TorchServe](https://github.com/pytorch/serve)

* [KubeFlow Serving](https://www.kubeflow.org/docs/components/serving/)

* [NVIDIA Triton](https://developer.nvidia.com/nvidia-triton-inference-server)